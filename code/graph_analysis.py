import pandas as pd
import numpy as np


class CreatingFormatToAnalysis:
    """
    This class takes Excel file with given Temperature/Intensity and T_stop data. This data is transformed and split
    into separate data frames that will be used in further analysis.
    """

    def __init__(self, excel_file):
        self.t_stop_data = []  # T_stop names data
        self.final_data_frames = []  # List with DataFrames contain Temperature and Intensity for each T_stop
        self.excel = pd.read_excel(excel_file)
        self.institute_apparatus = False
        if len(self.excel.columns) % 2 == 1:  # Only for files generated by this Program (Option INTiBS Folder)
            self.excel.drop([0, 1], inplace=True)
            self.excel = self.excel.drop('Unnamed: 0', axis='columns')
            self.excel = self.excel.reset_index(drop=True)
            self.institute_apparatus = True

        # Extraction T_stop values
        for col_name in self.excel.columns:
            if 'Unnamed' not in str(col_name):
                self.t_stop_data.append(col_name)

        # Extraction Temperatures and Intensities
        number_of_columns = len(self.excel.columns)
        for t_index, int_index in list(zip(range(0, number_of_columns, 2), range(1, number_of_columns, 2))):
            temp_data = self.excel.iloc[:, t_index].astype('float')
            int_data = self.excel.iloc[:, int_index].astype('float')
            temporary_pandas_file_to_sort = pd.DataFrame({'Temp': temp_data, 'Int': int_data})
            temporary_pandas_file = temporary_pandas_file_to_sort.sort_values(by='Temp')

            self.final_data_frames.append(temporary_pandas_file)  # Saving into class attribute


class PlotAnalysis:
    """
    The class contains two crucial methods:

        -> Mean of intensity points: That function creates an average intensity value on interval of temperature data.

        That is important to decrease the numbers of data and make analysis on a cleaned model (without noise)

        -> Peak Finder: That function finds the first intensity peak in the chart.
    """

    def __init__(self, data_frame):
        self.data_frame = data_frame  # Raw data from excel file
        self.mean_df = 0  # Data with mean values
        self.fitted_df = 0  # Fitted value

    def mean_of_intensity_points(self):
        """
        Creating mean intensity value for temperature interval
        :return: mean dataframe, over_fitted_polynomial dataframe
        """

        min_temperature = self.data_frame['Temp'].min()
        max_temperature = self.data_frame['Temp'].max()

        temp_range = np.arange(min_temperature, max_temperature + 1, dtype=int)

        mean_intensity_points = []  # Mean Int Points
        mean_temp_points = []  # Mean Temp points

        for start, stop in list(
                zip(range(temp_range[0], temp_range.max() + 2, 2), range(temp_range[1], temp_range.max() + 2, 2))):
            intensities_in_temperature = self.data_frame[
                (self.data_frame['Temp'] >= start) & (self.data_frame['Temp'] < stop)]
            mean_intensity = intensities_in_temperature['Int'].mean()
            if mean_intensity is np.NAN:
                continue
            mean_intensity_points.append(mean_intensity)
            mean_temp_points.append(np.mean([start, stop]))

        df = pd.DataFrame({'Temp': mean_temp_points, 'Int': mean_intensity_points})
        df = df.sort_values(by='Temp')
        self.mean_df = df  # Mean DataFrame

        # Over fitted polynomial function
        cof = np.polyfit(self.mean_df['Temp'], self.mean_df['Int'], 10)
        polynomial_equation = np.poly1d(cof)
        fitted_intensity = [polynomial_equation(t) for t in mean_temp_points]

        df_fitted = pd.DataFrame({'Temp': mean_temp_points, 'Int': fitted_intensity})
        df_fitted = df_fitted.sort_values(by='Temp')
        self.fitted_df = df_fitted  # Over fitted DataFrame

    def peak_finder(self, dp=3, dn=5):
        """
        Finding the first temperature and intensity peak:

        1. Calculate average intensity values (to reduce data and remove noise)
        2. Define a maximum intensity and temperature
        3. Calculate the difference between the mean_values and over_fitted_values (np.diff())
        4. Check if there is a peak between maximum intensity and starting point analysis temperature
        5. If there is a peak we need to check if there is a flattened line before this obvious peak
        6. If there is no peak, we are checking if there is a flattened line

        :param dp: Explained in delta_plus_or_minus
        :param dn: Like above
        :return:
        """

        def delta_plus_or_minus(data):
            """
            If there are values less than 0 in the entire expected range, then we have a peak between the maximum
            value and the starting point => delta will be negative

            DP => Clear peak between MaxIntensity and the starting point
            DN => Growing function that can have a suspected flattened interval.

            :param data: DataFrame
            :return: Improved DataFrame with new columns
            """

            minus_indexes_mean = data[data['diff_Int_mean'] < 0]
            minus_indexes_fit = data[data['diff_Int_fit'] < 0]
            delta_value = False

            if len(minus_indexes_mean) > 0:
                if len(minus_indexes_fit) > 0:
                    delta_value = True

            return delta_value

        def diff_anomaly(data_version):
            """
            Calculate the difference between mean_intensity and over_fitted_value.
            Also adds a new columns divOT ( T - 10% between points, O-no difference)
            :param data_version: DataFrame to improve
            :return: Data
            """

            # Delete the lowest values
            data_version['c'] = pd.cut(data_version['Int_mean'], 7)  # 14%
            drop_range_1 = data_version['c'].unique()[0]

            # Create % difference between mean and over_fitted values
            data_to_divide_1 = list(data_version['diff_Int_mean'])
            data_to_divide_2 = data_to_divide_1.copy()[1:]
            data_to_divide_2.append(0)

            data_div = pd.DataFrame({'x': data_to_divide_1, 'y': data_to_divide_2})
            data_div['div%'] = abs(data_div['y']) / data_div['x'] * 100
            data_version['div%_mean'] = list(data_div['div%'])

            # divOT_mean information to finding shelf's
            data_version = data_version[data_version['c'] != drop_range_1].copy()
            data_version['divOT_mean'] = data_version['div%_mean'].apply(lambda x: 'T' if x <= 10 else 'O')

            # divOT_fit (like in divOT_mean)
            data_to_divide_1 = list(data_version['diff_Int_fit'])
            data_to_divide_2 = data_to_divide_1.copy()[1:]
            data_to_divide_2.append(0)

            data_div = pd.DataFrame({'x': data_to_divide_1, 'y': data_to_divide_2})
            data_div['div%_fit'] = abs(data_div['y']) / data_div['x'] * 100
            data_version['div%_fit'] = list(data_div['div%_fit'])
            data_version['divOT_fit'] = data_version['div%_fit'].apply(lambda x: 'T' if x <= 10 else 'O')

            return data_version

        def shelf_anomaly(data, n):
            """
            Check if there is a shelf. If number of T repeats n times in series, then there is a shelf.
            :param data: DataFrame with OT values
            :param n: n times repeats
            :return: Final temperature and (AlgoCode only for me)
            """

            code_number = 0
            max_index_shelf_anomaly = data.index[-1]

            data_with_T_shelf_anomaly = data[data['divOT_mean'] == 'T'].index
            for index_T_shelf_anomaly in data_with_T_shelf_anomaly:
                if index_T_shelf_anomaly + 4 > max_index_shelf_anomaly:
                    final_tmax_shelf_anomaly = data['Temp'][max_index_shelf_anomaly].copy()
                    break
                else:
                    data_set_suspect_shelf_anomaly = data.loc[index_T_shelf_anomaly:index_T_shelf_anomaly + n + 1,
                                                              :].copy()  # n=3 , N=5

                    num_of_T_shelf_anomaly = len(
                        data_set_suspect_shelf_anomaly[data_set_suspect_shelf_anomaly['divOT_mean'] == 'T'])
                    # n+2, Example n=3 -> N=5 ->3/5
                    if num_of_T_shelf_anomaly >= n:
                        final_tmax_shelf_anomaly = data_set_suspect_shelf_anomaly.sort_values(by=['diff_Int_fit'])
                        final_tmax_shelf_anomaly = final_tmax_shelf_anomaly.reset_index()['Temp'][0]
                        break
                    else:
                        code_number += 1

            return [final_tmax_shelf_anomaly, code_number]

        def fit(t_max, code):
            """
            Calculate T_max and Int_max by fitting using the quadratic function
            :param t_max: predicted T_max
            :param code: Information (nothing important)
            :return: T_max, Int_max
            """
            data = self.data_frame.reset_index(drop=True)
            shift_number = code.split('-')[-1]
            T_min = data['Temp'].min()
            T_max = data['Temp'].max()
            T_diff = T_max - T_min
            T_8 = (8 * T_diff) / 100
            delta_t = T_8 / 2
            t_suspend = float(t_max)

            # Fitting interval
            if shift_number == '0' or shift_number == 'DPFM':
                left_t = t_suspend - delta_t
                right_t = t_suspend + delta_t
            else:
                left_t = t_suspend - (delta_t + float(shift_number))
                right_t = t_suspend + delta_t

            data_to_fit = data[(data['Temp'] >= left_t) & (data['Temp'] <= right_t)].copy()

            # Creating fitting function
            temp_points = data_to_fit['Temp']
            coeff = np.polyfit(data_to_fit['Temp'], data_to_fit['Int'], 2)
            polynomial_equation = np.poly1d(coeff)
            fitted_intensity = [polynomial_equation(t) for t in temp_points]

            data_fitted = pd.DataFrame({'Temp': temp_points, 'Int': fitted_intensity})
            data_fitted = data_fitted.sort_values(by='Temp')

            int_max = data_fitted[data_fitted['Int'] == data_fitted['Int'].max()].index[0]
            T_fit = data_fitted.loc[int_max]['Temp']
            I_fit = data_fitted.loc[int_max]['Int']

            return T_fit, I_fit

        # Main algorythm function

        df_fitted = self.fitted_df
        df_mean = self.mean_df

        df_fitted = df_fitted.rename(columns={'Int': 'Int_fit'})
        df_mean = df_mean.rename(columns={'Int': 'Int_mean'})

        max_int = df_mean['Int_mean'].max()
        index_max_int = df_mean[df_mean['Int_mean'] == max_int].index[0]
        suspended_area = df_mean.iloc[:index_max_int + 1, :].copy()
        suspended_area['Int_fit'] = df_fitted.loc[:index_max_int + 1, 'Int_fit']

        alg_code = "None"
        # Starts analysis if more than 10 data points otherwise T_max calculated by (DataFrame.max())
        if len(suspended_area) <= 10:
            final_tmax = suspended_area[suspended_area['Int_mean'] == max_int]['Temp']
            alg_code = 'FM'  # First_max
        else:
            # Calculate difference between intensity values (mean_intensity and over_fitted)
            suspended_area['diff_Int_mean'] = suspended_area['Int_mean'].diff()
            suspended_area['diff_Int_fit'] = suspended_area['Int_fit'].diff()
            suspended_area.fillna(0, inplace=True)

            # New data_set that checked the anomaly
            data_set = diff_anomaly(suspended_area)

            # Estimating the DeltaPositive or Negative
            minus_indexes = delta_plus_or_minus(data_set)

            # Delta Positive (peak between max int and starting point)
            if minus_indexes is False:
                # Check if there is the shelf
                divOT_mean = list(data_set['divOT_mean'])[:-1]
                divOT_fit = list(data_set['divOT_fit'])[:-1]
                divOT_fusion = divOT_mean + divOT_fit
                # If there is no T (look at shelf anomaly for more details)
                if 'T' not in divOT_fusion:
                    final_tmax = data_set[data_set['Int_mean'] == max_int]['Temp']
                    alg_code = 'DPFM'  # Delta-Positive-First-Max
                else:
                    final_tmax_ = shelf_anomaly(data_set, dp)  # DP=3
                    final_tmax = final_tmax_[0]
                    code_n = final_tmax_[1]
                    alg_code = f'DP-{dp}-{code_n}'

            # Delta Negative (No peak, checking for shelf)
            else:

                max_index = data_set.index[-1]
                data_with_T = data_set[data_set['divOT_fit'] == 'T'].index

                minus_code = 0
                for index_T in data_with_T:

                    # When T is at the end of data set
                    if index_T + 4 > max_index:
                        final_tmax = data_set.loc[index_T, 'Temp']
                        alg_code = f'DN-FM-{minus_code}'  # Delta negative
                        break

                    # T in the middle of dataset
                    else:
                        suspected_shelf = data_set.loc[:index_T, :].copy()
                        suspected_shelf_temp = suspected_shelf.loc[index_T, 'Temp']
                        suspected_temp = shelf_anomaly(suspected_shelf, dn)  # 5

                        if suspected_temp[0] != suspected_shelf_temp:
                            final_tmax = suspected_temp[0]
                            alg_code = f'DN-{dn}-SS-{minus_code}-{suspected_temp[1]}'
                            break
                        else:
                            # Checking if T is continuously in next 3
                            data_set_suspect_shelf = data_set.loc[index_T:index_T + 3, :].copy()  # 4
                            num_of_T = len(data_set_suspect_shelf[data_set_suspect_shelf['divOT_fit'] == 'T'])
                            if num_of_T >= 3:
                                final_tmax = data_set.loc[index_T, 'Temp']
                                alg_code = f'DN-{dn}-{minus_code}'
                                break
                            else:
                                minus_code += 1

        t_M, i_M = fit(final_tmax, alg_code)

        return t_M, i_M
